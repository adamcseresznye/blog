{
  "hash": "e5d3488a5d4381c9eea193927e61f97a",
  "result": {
    "markdown": "---\ntitle: Getting Started with Polars\nauthor: Adam Cseresznye\ndate: '2023-08-11'\ncategories:\n  - Polars\ntoc: true\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n---\n\n\n![](https://raw.githubusercontent.com/pola-rs/polars-static/master/web/splash.png){fig-align=\"center\" width=80%}\n\nIn the ever-evolving field of data science, effective data manipulation tools are essential. Enter Polars, a Rust-based library garnering attention within the data community. Boasting impressive speed and versatile capabilities, Polars is redefining our data management practices. In this blog, we delve into Polars' core functions and practical applications, shedding light on how it empowers data professionals to efficiently tackle complex tasks.\n\nFor those well-versed in Pandas, Polars offers a blend of familiarity and innovation. Although this document is not designed to substitute the official documentation, it serves as a tool to provide you with insights into the capabilities that polars offers. Our goal is to ensure the continuous updating of this document.\n\nOur exploration of Polars is guided by insights from the [Polars User Guide](https://pola-rs.github.io/polars-book/user-guide/), Kevin Heavey's perspectives in [Modern Polars](https://kevinheavey.github.io/modern-polars/) and Matt Harrison's [engaging tutorial](https://www.youtube.com/watch?v=CJ0f45evuME) on Polars at PyCon.\nWe kickstart our exploration with Matt Harrison's shared dataset, the US Department of Energy's [Automobile Fuel Economy data](https://github.com/mattharrison/datasets/blob/master/data/vehicles.csv.zip). Let's begin this journey! \n\n# Setup\n\n::: {.cell tags='[]' execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport polars as pl\nimport polars.selectors as cs\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\npl.Config.set_tbl_rows(2)  # limit the numbers of rows printed\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\npolars.config.Config\n```\n:::\n:::\n\n\n# Polars Version\n\nWe are using Polars 0.18.8 for this demonstration.\n\n::: {.cell tags='[]' execution_count=2}\n``` {.python .cell-code}\npl.__version__\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n'0.18.8'\n```\n:::\n:::\n\n\nGiven the large size of the dataset and the fact that some columns aren't really useful for us, we'll start by picking out the information we actually need. Feel free to use the code below to work with your dataframe.\n\n::: {.cell tags='[]' execution_count=3}\n``` {.python .cell-code}\ndf = pl.read_csv(\"vehicles.csv\", null_values=\"NA\")\n\n# process and save parquet for later use\n(\n    df.select(\n        pl.col(\n            \"make\",\n            \"model\",\n            \"drive\",\n            \"cylinders\",\n            \"displ\",\n            \"fuelType\",\n            \"mpgData\",\n            \"city08\",\n            \"highway08\",\n            \"comb08\",\n            \"year\",\n        )\n    )\n    .with_columns(\n        pl.col(\"make\").cast(pl.Categorical, strict=False),\n        pl.col(\"model\").cast(pl.Categorical, strict=False),\n        pl.col(\"drive\").cast(pl.Categorical, strict=False),\n        pl.col(\"fuelType\").cast(pl.Categorical, strict=False),\n        pl.col(\"cylinders\").cast(pl.Int8, strict=False),\n        pl.col(\"displ\").cast(pl.Float32, strict=False),\n        pl.col(\"mpgData\").map_dict({\"N\": False, \"Y\": True}),\n        pl.col(\"city08\").cast(pl.Int8, strict=False),\n        pl.col(\"highway08\").cast(pl.Int8, strict=False),\n        pl.col(\"comb08\").cast(pl.Int8, strict=False),\n        pl.col(\"year\").cast(pl.Utf8).str.to_datetime(\"%Y\").cast(pl.Date),\n    )\n    .write_parquet(\"vehicles.parquet\")\n)\ndf = pl.read_parquet(\"vehicles.parquet\")\n```\n:::\n\n\n# Inspect the polars namespace \n\nTaking a closer look at the Polars namespace can be really helpful as you start to get to know the library. By exploring the functions, methods, and attributes available within the namespace, you'll get a better sense of what the library can do. This exploration sets the groundwork for you to use the library more effectively and make the most of its features.\n\nBy issuing `print(dir(pl))`, we can explore the accessible functions within the namespace.\n\n::: {.cell tags='[]' execution_count=4}\n``` {.python .cell-code}\n# available functions\n\nprint(dir(pl))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['Array', 'ArrowError', 'Binary', 'Boolean', 'Categorical', 'ChronoFormatWarning', 'ColumnNotFoundError', 'ComputeError', 'Config', 'DATETIME_DTYPES', 'DURATION_DTYPES', 'DataFrame', 'DataType', 'Date', 'Datetime', 'Decimal', 'DuplicateError', 'Duration', 'Expr', 'FLOAT_DTYPES', 'Field', 'Float32', 'Float64', 'INTEGER_DTYPES', 'Int16', 'Int32', 'Int64', 'Int8', 'InvalidOperationError', 'LazyFrame', 'List', 'NUMERIC_DTYPES', 'NoDataError', 'Null', 'Object', 'PolarsDataType', 'PolarsPanicError', 'SQLContext', 'SchemaError', 'SchemaFieldNotFoundError', 'Series', 'ShapeError', 'StringCache', 'Struct', 'StructFieldNotFoundError', 'TEMPORAL_DTYPES', 'Time', 'UInt16', 'UInt32', 'UInt64', 'UInt8', 'Unknown', 'Utf8', '__all__', '__annotations__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__register_startup_deps', '__spec__', '__version__', '_reexport', 'align_frames', 'all', 'all_horizontal', 'any', 'any_horizontal', 'api', 'apply', 'approx_unique', 'arange', 'arg_sort_by', 'arg_where', 'avg', 'build_info', 'coalesce', 'col', 'collect_all', 'concat', 'concat_list', 'concat_str', 'config', 'contextlib', 'convert', 'corr', 'count', 'cov', 'cumfold', 'cumreduce', 'cumsum', 'cumsum_horizontal', 'dataframe', 'datatypes', 'date', 'date_range', 'datetime', 'dependencies', 'duration', 'element', 'enable_string_cache', 'exceptions', 'exclude', 'expr', 'first', 'fold', 'format', 'from_arrow', 'from_dataframe', 'from_dict', 'from_dicts', 'from_epoch', 'from_numpy', 'from_pandas', 'from_records', 'from_repr', 'functions', 'get_idx_type', 'get_index_type', 'groups', 'head', 'implode', 'int_range', 'int_ranges', 'io', 'last', 'lazyframe', 'lit', 'map', 'max', 'max_horizontal', 'mean', 'median', 'min', 'min_horizontal', 'n_unique', 'ones', 'os', 'polars', 'quantile', 'read_avro', 'read_csv', 'read_csv_batched', 'read_database', 'read_delta', 'read_excel', 'read_ipc', 'read_ipc_schema', 'read_json', 'read_ndjson', 'read_parquet', 'read_parquet_schema', 'reduce', 'repeat', 'rolling_corr', 'rolling_cov', 'scan_csv', 'scan_delta', 'scan_ds', 'scan_ipc', 'scan_ndjson', 'scan_parquet', 'scan_pyarrow_dataset', 'select', 'selectors', 'series', 'show_versions', 'slice', 'sql', 'sql_expr', 'std', 'string_cache', 'struct', 'sum', 'sum_horizontal', 'tail', 'threadpool_size', 'time', 'time_range', 'toggle_string_cache', 'type_aliases', 'using_string_cache', 'utils', 'var', 'when', 'wrap_df', 'wrap_s', 'zeros']\n```\n:::\n:::\n\n\nThe same applies to the methods available for DataFrames.\n\n::: {.cell tags='[]' execution_count=5}\n``` {.python .cell-code}\n# methods defined on dataframes\n\nprint(dir(df))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['__add__', '__annotations__', '__array__', '__bool__', '__class__', '__contains__', '__copy__', '__dataframe__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__module__', '__mul__', '__ne__', '__new__', '__radd__', '__reduce__', '__reduce_ex__', '__repr__', '__rmul__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '_accessors', '_cast_all_from_to', '_comp', '_compare_to_non_df', '_compare_to_other_df', '_df', '_div', '_from_arrow', '_from_dict', '_from_dicts', '_from_numpy', '_from_pandas', '_from_pydf', '_from_records', '_ipython_key_completions_', '_pos_idx', '_read_avro', '_read_csv', '_read_ipc', '_read_json', '_read_ndjson', '_read_parquet', '_repr_html_', '_take_with_series', 'apply', 'bottom_k', 'clear', 'clone', 'columns', 'corr', 'describe', 'drop', 'drop_in_place', 'drop_nulls', 'dtypes', 'estimated_size', 'explode', 'extend', 'fill_nan', 'fill_null', 'filter', 'find_idx_by_name', 'fold', 'frame_equal', 'get_column', 'get_columns', 'glimpse', 'groupby', 'groupby_dynamic', 'groupby_rolling', 'hash_rows', 'head', 'height', 'hstack', 'insert_at_idx', 'interpolate', 'is_duplicated', 'is_empty', 'is_unique', 'item', 'iter_rows', 'iter_slices', 'join', 'join_asof', 'lazy', 'limit', 'max', 'mean', 'median', 'melt', 'merge_sorted', 'min', 'n_chunks', 'n_unique', 'null_count', 'partition_by', 'pipe', 'pivot', 'product', 'quantile', 'rechunk', 'rename', 'replace', 'replace_at_idx', 'reverse', 'row', 'rows', 'rows_by_key', 'sample', 'schema', 'select', 'set_sorted', 'shape', 'shift', 'shift_and_fill', 'shrink_to_fit', 'slice', 'sort', 'std', 'sum', 'tail', 'take_every', 'to_arrow', 'to_dict', 'to_dicts', 'to_dummies', 'to_init_repr', 'to_numpy', 'to_pandas', 'to_series', 'to_struct', 'top_k', 'transpose', 'unique', 'unnest', 'unstack', 'update', 'upsample', 'var', 'vstack', 'width', 'with_columns', 'with_row_count', 'write_avro', 'write_csv', 'write_database', 'write_delta', 'write_excel', 'write_ipc', 'write_json', 'write_ndjson', 'write_parquet']\n```\n:::\n:::\n\n\n...and expressions for the Series\n\n::: {.cell tags='[]' execution_count=6}\n``` {.python .cell-code}\n# available expressions\n\nprint(dir(pl.col(\"foo\")))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['__abs__', '__add__', '__and__', '__annotations__', '__array_ufunc__', '__bool__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__le__', '__lt__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmod__', '__rmul__', '__ror__', '__rpow__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__weakref__', '__xor__', '_accessors', '_from_pyexpr', '_pyexpr', '_repr_html_', '_to_expr', '_to_pyexpr', 'abs', 'add', 'agg_groups', 'alias', 'all', 'and_', 'any', 'append', 'apply', 'approx_unique', 'arccos', 'arccosh', 'arcsin', 'arcsinh', 'arctan', 'arctanh', 'arg_max', 'arg_min', 'arg_sort', 'arg_true', 'arg_unique', 'arr', 'backward_fill', 'bin', 'bottom_k', 'cache', 'cast', 'cat', 'cbrt', 'ceil', 'clip', 'clip_max', 'clip_min', 'cos', 'cosh', 'count', 'cumcount', 'cummax', 'cummin', 'cumprod', 'cumsum', 'cumulative_eval', 'cut', 'degrees', 'diff', 'dot', 'drop_nans', 'drop_nulls', 'dt', 'entropy', 'eq', 'eq_missing', 'ewm_mean', 'ewm_std', 'ewm_var', 'exclude', 'exp', 'explode', 'extend_constant', 'fill_nan', 'fill_null', 'filter', 'first', 'flatten', 'floor', 'floordiv', 'forward_fill', 'from_json', 'ge', 'gt', 'hash', 'head', 'implode', 'inspect', 'interpolate', 'is_between', 'is_duplicated', 'is_finite', 'is_first', 'is_in', 'is_infinite', 'is_nan', 'is_not', 'is_not_nan', 'is_not_null', 'is_null', 'is_unique', 'keep_name', 'kurtosis', 'last', 'le', 'len', 'limit', 'list', 'log', 'log10', 'log1p', 'lower_bound', 'lt', 'map', 'map_alias', 'map_dict', 'max', 'mean', 'median', 'meta', 'min', 'mod', 'mode', 'mul', 'n_unique', 'nan_max', 'nan_min', 'ne', 'ne_missing', 'null_count', 'or_', 'over', 'pct_change', 'pipe', 'pow', 'prefix', 'product', 'qcut', 'quantile', 'radians', 'rank', 'rechunk', 'reinterpret', 'repeat_by', 'reshape', 'reverse', 'rle', 'rle_id', 'rolling_apply', 'rolling_max', 'rolling_mean', 'rolling_median', 'rolling_min', 'rolling_quantile', 'rolling_skew', 'rolling_std', 'rolling_sum', 'rolling_var', 'round', 'sample', 'search_sorted', 'set_sorted', 'shift', 'shift_and_fill', 'shrink_dtype', 'shuffle', 'sign', 'sin', 'sinh', 'skew', 'slice', 'sort', 'sort_by', 'sqrt', 'std', 'str', 'struct', 'sub', 'suffix', 'sum', 'tail', 'take', 'take_every', 'tan', 'tanh', 'to_physical', 'top_k', 'truediv', 'unique', 'unique_counts', 'upper_bound', 'value_counts', 'var', 'where', 'xor']\n```\n:::\n:::\n\n\n# Access documentation\n\nIf you're familiar with Python, you might recognize that you can access documentation by either using `__doc__` or by calling the `help()` function.\n\n::: {.cell tags='[]' execution_count=7}\n``` {.python .cell-code}\nprint(df[\"year\"].dt.convert_time_zone.__doc__)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n        Convert to given time zone for a Series of type Datetime.\n\n        Parameters\n        ----------\n        time_zone\n            Time zone for the `Datetime` Series.\n\n        Examples\n        --------\n        >>> from datetime import datetime\n        >>> start = datetime(2020, 3, 1)\n        >>> stop = datetime(2020, 5, 1)\n        >>> date = pl.date_range(start, stop, \"1mo\", time_zone=\"UTC\", eager=True)\n        >>> date\n        shape: (3,)\n        Series: 'date' [datetime[μs, UTC]]\n        [\n                2020-03-01 00:00:00 UTC\n                2020-04-01 00:00:00 UTC\n                2020-05-01 00:00:00 UTC\n        ]\n        >>> date = date.dt.convert_time_zone(\"Europe/London\").alias(\"London\")\n        >>> date\n        shape: (3,)\n        Series: 'London' [datetime[μs, Europe/London]]\n        [\n            2020-03-01 00:00:00 GMT\n            2020-04-01 01:00:00 BST\n            2020-05-01 01:00:00 BST\n        ]\n        \n```\n:::\n:::\n\n\n::: {.cell tags='[]' execution_count=8}\n``` {.python .cell-code}\nhelp(pl.head)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHelp on function head in module polars.functions.lazy:\n\nhead(column: 'str | Series', n: 'int' = 10) -> 'Expr | Series'\n    Get the first `n` rows.\n    \n    Parameters\n    ----------\n    column\n        Column name or Series.\n    n\n        Number of rows to return.\n    \n    Examples\n    --------\n    >>> df = pl.DataFrame({\"a\": [1, 8, 3], \"b\": [4, 5, 2], \"c\": [\"foo\", \"bar\", \"foo\"]})\n    >>> df.select(pl.head(\"a\"))\n    shape: (3, 1)\n    ┌─────┐\n    │ a   │\n    │ --- │\n    │ i64 │\n    ╞═════╡\n    │ 1   │\n    │ 8   │\n    │ 3   │\n    └─────┘\n    >>> df.select(pl.head(\"a\", 2))\n    shape: (2, 1)\n    ┌─────┐\n    │ a   │\n    │ --- │\n    │ i64 │\n    ╞═════╡\n    │ 1   │\n    │ 8   │\n    └─────┘\n\n```\n:::\n:::\n\n\n# Indexing\n\nIf you've spent some time working with Pandas, you might find it interesting that Polars doesn't rely on the concept of an index like Pandas does. But no need to fret—there are several other ways we can still access the rows in Polars. One of the straightforward methods—although I won't delve too deeply into it here—is using the `head`, `tail`, and `sample` methods.\n\n## Use `take` for Series or Expressions\n\nAn interesting approach is through Polars' `take` method. This method can be used with `Expr`, `Series`, or `np.ndarray`. However, it's worth noting that if you intend to utilize it with DataFrames, a preliminary conversion to Series is necessary.\n\n::: {.cell .column-margin tags='[]' execution_count=9}\n``` {.python .cell-code}\ndf.select(pl.col(\"make\")).to_series().take(list(range(0, 5)))\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (5,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th></tr><tr><td>cat</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td></tr><tr><td>&hellip;</td></tr><tr><td>&quot;Subaru&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Using `filter`\n\nSimilar to Pandas, Polars features a `filter` method that assists in the process of selectively filtering rows based on one or multiple conditions.\n\n### Evaluate a single condition \n\n::: {.cell tags='[]' execution_count=10}\n``` {.python .cell-code}\ndf.filter(pl.col(\"model\") == \"Testarossa\")\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (14, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>drive</th><th>cylinders</th><th>displ</th><th>fuelType</th><th>mpgData</th><th>city08</th><th>highway08</th><th>comb08</th><th>year</th></tr><tr><td>cat</td><td>cat</td><td>cat</td><td>i8</td><td>f32</td><td>cat</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td><td>date</td></tr></thead><tbody><tr><td>&quot;Ferrari&quot;</td><td>&quot;Testarossa&quot;</td><td>&quot;Rear-Wheel Dri…</td><td>12</td><td>4.9</td><td>&quot;Regular&quot;</td><td>false</td><td>9</td><td>14</td><td>11</td><td>1985-01-01</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Ferrari&quot;</td><td>&quot;Testarossa&quot;</td><td>&quot;Rear-Wheel Dri…</td><td>12</td><td>4.9</td><td>&quot;Premium&quot;</td><td>false</td><td>10</td><td>15</td><td>11</td><td>1992-01-01</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n### Combine multiple conditions\n\n::: {.cell tags='[]' execution_count=11}\n``` {.python .cell-code}\ndf.filter((pl.col(\"model\") == \"Testarossa\") & (pl.col(\"make\") == \"Ferrari\"))\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (9, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>drive</th><th>cylinders</th><th>displ</th><th>fuelType</th><th>mpgData</th><th>city08</th><th>highway08</th><th>comb08</th><th>year</th></tr><tr><td>cat</td><td>cat</td><td>cat</td><td>i8</td><td>f32</td><td>cat</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td><td>date</td></tr></thead><tbody><tr><td>&quot;Ferrari&quot;</td><td>&quot;Testarossa&quot;</td><td>&quot;Rear-Wheel Dri…</td><td>12</td><td>4.9</td><td>&quot;Regular&quot;</td><td>false</td><td>9</td><td>14</td><td>11</td><td>1985-01-01</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Ferrari&quot;</td><td>&quot;Testarossa&quot;</td><td>&quot;Rear-Wheel Dri…</td><td>12</td><td>4.9</td><td>&quot;Premium&quot;</td><td>false</td><td>10</td><td>15</td><td>11</td><td>1992-01-01</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Imitate pandas' `index` using `with_row_count`\n\nEven in the absence of a traditional index, you can make use of the `with_row_count` method in Polars. This clever method comes to the rescue for tasks like indexing and filtering, providing an alternative approach.\n\n::: {.cell tags='[]' execution_count=12}\n``` {.python .cell-code}\n(df.with_row_count().filter(pl.col(\"row_nr\") == 5))\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (1, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_nr</th><th>make</th><th>model</th><th>drive</th><th>cylinders</th><th>displ</th><th>fuelType</th><th>mpgData</th><th>city08</th><th>highway08</th><th>comb08</th><th>year</th></tr><tr><td>u32</td><td>cat</td><td>cat</td><td>cat</td><td>i8</td><td>f32</td><td>cat</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td><td>date</td></tr></thead><tbody><tr><td>5</td><td>&quot;Subaru&quot;</td><td>&quot;Loyale&quot;</td><td>&quot;Front-Wheel Dr…</td><td>4</td><td>1.8</td><td>&quot;Regular&quot;</td><td>false</td><td>21</td><td>24</td><td>22</td><td>1993-01-01</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n### Use `is_in`\n\nThe `is_in` function can be employed to verify whether elements of a given expression are present within another Series. We can use this to filter our rows.\n\n::: {.cell tags='[]' execution_count=13}\n``` {.python .cell-code}\ndf.filter(pl.col(\"cylinders\").is_in([i for i in range(6, 8)]))\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (14_284, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>drive</th><th>cylinders</th><th>displ</th><th>fuelType</th><th>mpgData</th><th>city08</th><th>highway08</th><th>comb08</th><th>year</th></tr><tr><td>cat</td><td>cat</td><td>cat</td><td>i8</td><td>f32</td><td>cat</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td><td>date</td></tr></thead><tbody><tr><td>&quot;Audi&quot;</td><td>&quot;100&quot;</td><td>&quot;Front-Wheel Dr…</td><td>6</td><td>2.8</td><td>&quot;Premium&quot;</td><td>true</td><td>17</td><td>22</td><td>19</td><td>1993-01-01</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Pontiac&quot;</td><td>&quot;Grand Am&quot;</td><td>&quot;Front-Wheel Dr…</td><td>6</td><td>3.3</td><td>&quot;Regular&quot;</td><td>false</td><td>18</td><td>26</td><td>21</td><td>1993-01-01</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n# Select columns\n\nBefore we dive into the realm of selecting columns, it's important to introduce the concepts of `with_columns` and `select`, while also highlighting the distinctions between these two methods.\n\n## Difference between `select` and  with_columns`\n\nAs evident from the examples below, both `select` and `with_column` can be utilized for both column selection and column assignment. However, there's a crucial distinction between the two. After performing column operations, the `select` method drops the unselected columns and retains only the columns that underwent operations. Conversely, the `with_column` method appends the new columns to the dataframe, preserving the original ones.\n\n::: {.cell .column-margin tags='[]' execution_count=14}\n``` {.python .cell-code}\n# everything else is dropped\n\n(\n    df.select(\n        (pl.col(\"city08\") + 10).alias(\"added\"),\n        (pl.col(\"city08\") - 10).alias(\"substracted\"),\n    )\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>added</th><th>substracted</th></tr><tr><td>i8</td><td>i8</td></tr></thead><tbody><tr><td>29</td><td>9</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>26</td><td>6</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n::: {.cell tags='[]' execution_count=15}\n``` {.python .cell-code}\n# columns are kept\n\n(\n    df.with_columns(\n        (pl.col(\"city08\") + 10).alias(\"added\"),\n        (pl.col(\"city08\") - 10).alias(\"substracted\"),\n    )\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>drive</th><th>cylinders</th><th>displ</th><th>fuelType</th><th>mpgData</th><th>city08</th><th>highway08</th><th>comb08</th><th>year</th><th>added</th><th>substracted</th></tr><tr><td>cat</td><td>cat</td><td>cat</td><td>i8</td><td>f32</td><td>cat</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td><td>date</td><td>i8</td><td>i8</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td><td>&quot;Spider Veloce …</td><td>&quot;Rear-Wheel Dri…</td><td>4</td><td>2.0</td><td>&quot;Regular&quot;</td><td>true</td><td>19</td><td>25</td><td>21</td><td>1985-01-01</td><td>29</td><td>9</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Subaru&quot;</td><td>&quot;Legacy AWD Tur…</td><td>&quot;4-Wheel or All…</td><td>4</td><td>2.2</td><td>&quot;Premium&quot;</td><td>false</td><td>16</td><td>21</td><td>18</td><td>1993-01-01</td><td>26</td><td>6</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nNow that we've clarified this point, let's proceed to explore the fundamental methods for selecting columns. \n\n## Select all columns\n\nA particularly handy tool is `pl.all()`, which provides the current state of the dataframe—similar to `pd.assign(foo=lambda df)` in Pandas. This can prove useful, particularly when dealing with operations like groupby and aggregation. \n\n::: {.cell tags='[]' execution_count=16}\n``` {.python .cell-code}\n# this is analogous to df.select(pl.col(\"*\")), where * represents the wildcard component\ndf.select(pl.all())\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>drive</th><th>cylinders</th><th>displ</th><th>fuelType</th><th>mpgData</th><th>city08</th><th>highway08</th><th>comb08</th><th>year</th></tr><tr><td>cat</td><td>cat</td><td>cat</td><td>i8</td><td>f32</td><td>cat</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td><td>date</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td><td>&quot;Spider Veloce …</td><td>&quot;Rear-Wheel Dri…</td><td>4</td><td>2.0</td><td>&quot;Regular&quot;</td><td>true</td><td>19</td><td>25</td><td>21</td><td>1985-01-01</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Subaru&quot;</td><td>&quot;Legacy AWD Tur…</td><td>&quot;4-Wheel or All…</td><td>4</td><td>2.2</td><td>&quot;Premium&quot;</td><td>false</td><td>16</td><td>21</td><td>18</td><td>1993-01-01</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Select all columns except for...\n\n::: {.cell tags='[]' execution_count=17}\n``` {.python .cell-code}\ndf.select(pl.col(\"*\").exclude(\"year\", \"comb08\", \"highway08\"))\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>drive</th><th>cylinders</th><th>displ</th><th>fuelType</th><th>mpgData</th><th>city08</th></tr><tr><td>cat</td><td>cat</td><td>cat</td><td>i8</td><td>f32</td><td>cat</td><td>bool</td><td>i8</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td><td>&quot;Spider Veloce …</td><td>&quot;Rear-Wheel Dri…</td><td>4</td><td>2.0</td><td>&quot;Regular&quot;</td><td>true</td><td>19</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Subaru&quot;</td><td>&quot;Legacy AWD Tur…</td><td>&quot;4-Wheel or All…</td><td>4</td><td>2.2</td><td>&quot;Premium&quot;</td><td>false</td><td>16</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Select a subset of columns\n\n::: {.cell .column-margin tags='[]' execution_count=18}\n``` {.python .cell-code}\ndf.select(pl.col(\"year\", \"comb08\", \"highway08\"))\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>comb08</th><th>highway08</th></tr><tr><td>date</td><td>i8</td><td>i8</td></tr></thead><tbody><tr><td>1985-01-01</td><td>21</td><td>25</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1993-01-01</td><td>18</td><td>21</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Select columns based on regular expression \n\n::: {.cell .column-margin tags='[]' execution_count=19}\n``` {.python .cell-code}\ndf.select(pl.col(\"^.*(mo|ma).*$\"))\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th></tr><tr><td>cat</td><td>cat</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td><td>&quot;Spider Veloce …</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Subaru&quot;</td><td>&quot;Legacy AWD Tur…</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Select columns based on dtypes\n\nThis may remind you of pandas' `select_dtypes` method.\n\n::: {.cell tags='[]' execution_count=20}\n``` {.python .cell-code}\ndf.select(pl.col(pl.Int8, pl.Boolean))\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>cylinders</th><th>mpgData</th><th>city08</th><th>highway08</th><th>comb08</th></tr><tr><td>i8</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td></tr></thead><tbody><tr><td>4</td><td>true</td><td>19</td><td>25</td><td>21</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>4</td><td>false</td><td>16</td><td>21</td><td>18</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Using `selectors`\n\nSelectors offer a more intuitive approach to selecting columns from DataFrame or LazyFrame objects, taking into account factors like column names, data types, and other properties. They consolidate and enhance the functionality that's accessible through the `col()` expression. More on them [here](https://pola-rs.github.io/polars/py-polars/html/reference/selectors.html#selectors).\n\n### By dtypes\n\n::: {.cell tags='[]' execution_count=21}\n``` {.python .cell-code}\ndf.select(cs.integer(), cs.float(), cs.temporal())\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>cylinders</th><th>city08</th><th>highway08</th><th>comb08</th><th>displ</th><th>year</th></tr><tr><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>f32</td><td>date</td></tr></thead><tbody><tr><td>4</td><td>19</td><td>25</td><td>21</td><td>2.0</td><td>1985-01-01</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>4</td><td>16</td><td>21</td><td>18</td><td>2.2</td><td>1993-01-01</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n::: {.cell tags='[]' execution_count=22}\n``` {.python .cell-code}\n# all columns except for the ones containing float\ndf.select(cs.all() - cs.numeric())\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>drive</th><th>fuelType</th><th>mpgData</th><th>year</th></tr><tr><td>cat</td><td>cat</td><td>cat</td><td>cat</td><td>bool</td><td>date</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td><td>&quot;Spider Veloce …</td><td>&quot;Rear-Wheel Dri…</td><td>&quot;Regular&quot;</td><td>true</td><td>1985-01-01</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Subaru&quot;</td><td>&quot;Legacy AWD Tur…</td><td>&quot;4-Wheel or All…</td><td>&quot;Premium&quot;</td><td>false</td><td>1993-01-01</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n::: {.cell tags='[]' execution_count=23}\n``` {.python .cell-code}\n# same as the one above but it uses the tilde\ndf.select(~cs.numeric())\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>drive</th><th>fuelType</th><th>mpgData</th><th>year</th></tr><tr><td>cat</td><td>cat</td><td>cat</td><td>cat</td><td>bool</td><td>date</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td><td>&quot;Spider Veloce …</td><td>&quot;Rear-Wheel Dri…</td><td>&quot;Regular&quot;</td><td>true</td><td>1985-01-01</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Subaru&quot;</td><td>&quot;Legacy AWD Tur…</td><td>&quot;4-Wheel or All…</td><td>&quot;Premium&quot;</td><td>false</td><td>1993-01-01</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n### By column names\n\n::: {.cell .column-margin tags='[]' execution_count=24}\n``` {.python .cell-code}\ndf.select(cs.contains(\"08\"))\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>city08</th><th>highway08</th><th>comb08</th></tr><tr><td>i8</td><td>i8</td><td>i8</td></tr></thead><tbody><tr><td>19</td><td>25</td><td>21</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>16</td><td>21</td><td>18</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n::: {.cell .column-margin tags='[]' execution_count=25}\n``` {.python .cell-code}\ndf.select(cs.starts_with(\"d\"))\n```\n\n::: {.cell-output .cell-output-display execution_count=25}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>drive</th><th>displ</th></tr><tr><td>cat</td><td>f32</td></tr></thead><tbody><tr><td>&quot;Rear-Wheel Dri…</td><td>2.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4-Wheel or All…</td><td>2.2</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThe possibilities here are incredibly vast! I'm pretty sure you'll find a function that suits your needs just right.\n\n# `dtype` conversions\n\nUnderstanding and managing data types, as well as converting them, are very important—particularly when dealing with larger datasets. Luckily, with Polars, this process is wonderfully straightforward. Here's a useful tip: in many cases, the `cast` method will be your trusty companion for data type conversions. It's quite versatile and often does the job seamlessly. When it comes to converting dates, things can get a bit more intricate, but rest assured, it's a hurdle you can easily overcome!\n\nMore info on the available dtypes can be found [here](https://pola-rs.github.io/polars-book/user-guide/concepts/data-types/).\n\n::: {.cell .column-margin tags='[]' execution_count=26}\n``` {.python .cell-code}\n(\n    df.select(\n        pl.col(\"cylinders\").cast(pl.Int32),\n        pl.col(\"displ\").cast(pl.Int64),\n        pl.col(\"mpgData\").cast(pl.Int64),\n    )\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>cylinders</th><th>displ</th><th>mpgData</th></tr><tr><td>i32</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>4</td><td>2</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>4</td><td>2</td><td>0</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n# Working with `str`\n\nWe can examine the available attributes when working with strings. You might notice that it boasts some familiar attributes, like `extract`, `replace`, `split`, and `strip`, among others.\n\n::: {.cell tags='[]' execution_count=27}\n``` {.python .cell-code}\n# attributes of str\nprint(dir(pl.col(\"*\").str))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_accessor', '_pyexpr', 'concat', 'contains', 'count_match', 'decode', 'encode', 'ends_with', 'explode', 'extract', 'extract_all', 'json_extract', 'json_path_match', 'lengths', 'ljust', 'lstrip', 'n_chars', 'parse_int', 'replace', 'replace_all', 'rjust', 'rstrip', 'slice', 'split', 'split_exact', 'splitn', 'starts_with', 'strip', 'strptime', 'to_date', 'to_datetime', 'to_decimal', 'to_lowercase', 'to_time', 'to_titlecase', 'to_uppercase', 'zfill']\n```\n:::\n:::\n\n\n## Basic operations\n\n::: {.cell tags='[]' execution_count=28}\n``` {.python .cell-code}\n(\n    df.select(\n        pl.col(\"make\").cast(pl.Utf8).str.contains(\"Hyundai|Kia\").alias(\"contains\"),\n        pl.col(\"make\").cast(pl.Utf8).str.starts_with(\"Alfa\").alias(\"starts_with\"),\n        pl.col(\"make\").cast(pl.Utf8).str.ends_with(\"ari\").alias(\"ends_with\"),\n    )\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>contains</th><th>starts_with</th><th>ends_with</th></tr><tr><td>bool</td><td>bool</td><td>bool</td></tr></thead><tbody><tr><td>false</td><td>true</td><td>false</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>false</td><td>false</td><td>false</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nWe can extract the numbers from the different car models:\n\n::: {.cell .column-margin tags='[]' execution_count=29}\n``` {.python .cell-code}\n(\n    df.select(\n        pl.col(\"model\")\n        .cast(pl.Utf8)\n        .str.extract(r\"(\\d+)\", group_index=1)\n        .cast(pl.Int32)\n        .alias(\"extracted_number\"),\n    )\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>extracted_number</th></tr><tr><td>i32</td></tr></thead><tbody><tr><td>2000</td></tr><tr><td>&hellip;</td></tr><tr><td>null</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nAs per usual, we can replace values in a given column:\n\n::: {.cell .column-margin tags='[]' execution_count=30}\n``` {.python .cell-code}\n(\n    df.select(\n        pl.col(\"make\").cast(pl.Utf8).str.replace(\"r\", 0).alias(\"replaced\"),\n    )\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>replaced</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td></tr><tr><td>&hellip;</td></tr><tr><td>&quot;Suba0u&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Changing column names\n\nAltering column names is quite reminiscent of the process in Pandas:\n\n::: {.cell tags='[]' execution_count=31}\n``` {.python .cell-code}\ndf.rename({\"make\": \"car maker\", \"model\": \"car model\"})\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>car maker</th><th>car model</th><th>drive</th><th>cylinders</th><th>displ</th><th>fuelType</th><th>mpgData</th><th>city08</th><th>highway08</th><th>comb08</th><th>year</th></tr><tr><td>cat</td><td>cat</td><td>cat</td><td>i8</td><td>f32</td><td>cat</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td><td>date</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td><td>&quot;Spider Veloce …</td><td>&quot;Rear-Wheel Dri…</td><td>4</td><td>2.0</td><td>&quot;Regular&quot;</td><td>true</td><td>19</td><td>25</td><td>21</td><td>1985-01-01</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Subaru&quot;</td><td>&quot;Legacy AWD Tur…</td><td>&quot;4-Wheel or All…</td><td>4</td><td>2.2</td><td>&quot;Premium&quot;</td><td>false</td><td>16</td><td>21</td><td>18</td><td>1993-01-01</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nIn case you would like to alter multiple column names all at once:\n\n::: {.cell tags='[]' execution_count=32}\n``` {.python .cell-code}\ndf.select(pl.all().map_alias(lambda name: name.upper().replace(\"I\", \"0000\")))\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>MAKE</th><th>MODEL</th><th>DR0000VE</th><th>CYL0000NDERS</th><th>D0000SPL</th><th>FUELTYPE</th><th>MPGDATA</th><th>C0000TY08</th><th>H0000GHWAY08</th><th>COMB08</th><th>YEAR</th></tr><tr><td>cat</td><td>cat</td><td>cat</td><td>i8</td><td>f32</td><td>cat</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td><td>date</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td><td>&quot;Spider Veloce …</td><td>&quot;Rear-Wheel Dri…</td><td>4</td><td>2.0</td><td>&quot;Regular&quot;</td><td>true</td><td>19</td><td>25</td><td>21</td><td>1985-01-01</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Subaru&quot;</td><td>&quot;Legacy AWD Tur…</td><td>&quot;4-Wheel or All…</td><td>4</td><td>2.2</td><td>&quot;Premium&quot;</td><td>false</td><td>16</td><td>21</td><td>18</td><td>1993-01-01</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n### `str.split` with `expand='all'`\n\n\nI often find myself using the `str.split` method, and it caught me off guard that there isn't a direct equivalent in Polars. Fingers crossed, we might come across an implementation like `expand=True` from Pandas, which would be a real game-changer here too!\n\n::: {.cell .column-margin tags='[]' execution_count=33}\n``` {.python .cell-code}\n(\n    df.select(\n        pl.col(\"drive\")\n        .cast(pl.Utf8)\n        .str.split_exact(\"-\", n=1)\n        .struct.rename_fields([\"first_part\", \"second_part\"])\n        .alias(\"fields\"),\n    ).unnest(\"fields\")\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>first_part</th><th>second_part</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Rear&quot;</td><td>&quot;Wheel Drive&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4&quot;</td><td>&quot;Wheel or All&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n# Aggregation\n\nSplit-apply-combine operations are where Polars truly excels. This is largely due to its foundation in Rust, Polars' use of lazy evaluation, parallel execution, and efficient memory management also contribute to its speed. As a result, split-apply-combine operations are significantly faster in Polars compared to conventional methods.\n\n## A simple split-apply-combine operation\n\n::: {.cell .column-margin tags='[]' execution_count=34}\n``` {.python .cell-code}\n(df.groupby(\"make\").count().sort(by=\"count\", descending=True).limit(5))\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>count</th></tr><tr><td>cat</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Chevrolet&quot;</td><td>4003</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Toyota&quot;</td><td>2071</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Using `agg`\n\nYou can use `agg` to calculate statistics over either a single or multiple columns all at once.\n\n::: {.cell tags='[]' execution_count=35}\n``` {.python .cell-code}\n(df.groupby(\"make\").agg(pl.count(), pl.col(\"model\")))\n```\n\n::: {.cell-output .cell-output-display execution_count=35}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (136, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>count</th><th>model</th></tr><tr><td>cat</td><td>u32</td><td>list[cat]</td></tr></thead><tbody><tr><td>&quot;TVR Engineerin…</td><td>4</td><td>[&quot;TVR 280i/350i Convertible&quot;, &quot;TVR 280i/350i Coupe&quot;, … &quot;TVR 280i Coupe&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Grumman Allied…</td><td>1</td><td>[&quot;LLV&quot;]</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nHere's an illustration of how to utilize the `is_not_nan` method. In Polars, unknown values are represented with floating-point precision, similar to how pandas handles them. It's important not to mix this up with missing values, which are indicated by `Null` in Polars. Additionally, take note of the use of `limit` instead of `head`, a concept quite akin to SQL.\n\n::: {.cell tags='[]' execution_count=36}\n``` {.python .cell-code}\n(\n    df.groupby(\"make\")\n    .agg(\n        pl.col(\"city08\").mean().alias(\"mean_cyl\"),\n        pl.col(\"displ\").mean().alias(\"mean_disp\"),\n    )\n    .filter(pl.col(\"mean_cyl\").is_not_nan())\n    .sort(by=[\"mean_cyl\", \"mean_disp\"], descending=[True, True])\n    .limit(5)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=36}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>mean_cyl</th><th>mean_disp</th></tr><tr><td>cat</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Tesla&quot;</td><td>94.925373</td><td>NaN</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Azure Dynamics…</td><td>62.0</td><td>NaN</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nAggregated columns can be renamed immediately with the `alias` method.\n\n::: {.cell tags='[]' execution_count=37}\n``` {.python .cell-code}\n(\n    df.groupby(\"make\", \"fuelType\")\n    .agg(pl.col(\"comb08\").mean().alias(\"filtered\"))\n    .filter((pl.col(\"fuelType\") == \"CNG\") | (pl.col(\"fuelType\") == \"Diesel\"))\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (38, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>fuelType</th><th>filtered</th></tr><tr><td>cat</td><td>cat</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Mazda&quot;</td><td>&quot;Diesel&quot;</td><td>29.714286</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Ford&quot;</td><td>&quot;Diesel&quot;</td><td>29.542857</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nHere's a scenario for performing aggregation based on the year. In this case, the \"year\" column holds the year-related data, which can be extracted using the `dt.year` attribute. Keep in mind that Polars doesn't have native plotting capabilities like pandas. To visualize the data, as a final step, you can convert the dataframe to pandas and make use of its `.plot` method.\n\n::: {.cell tags='[]' execution_count=38}\n``` {.python .cell-code}\n(\n    df.groupby(\n        [\n            pl.col(\"year\").dt.year().alias(\"year\"),\n        ]\n    )\n    .agg([pl.col(\"comb08\").mean(), pl.col(\"city08\").mean()])\n    .sort(\n        [\n            \"year\",\n        ]\n    )\n    .to_pandas()\n    .set_index(\"year\")\n    .plot()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```\n<Axes: xlabel='year'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Polars_revised_files/figure-html/cell-39-output-2.png){width=566 height=429}\n:::\n:::\n\n\nHere's another fantastic option for you: the `groupby_dynamic` feature. It's really impressive, by the way. You can employ this when grouping based on years or any other time-related information. Additionally, you can make use of the `every` parameter for resampling, which closely resembles what you can do with pandas.\n\n::: {.cell tags='[]' execution_count=39}\n``` {.python .cell-code}\n(\n    df.sort(by=\"year\")\n    .groupby_dynamic(index_column=\"year\", every=\"2y\")\n    .agg([pl.col(\"comb08\").mean(), pl.col(\"city08\").mean()])\n    .sort(\n        [\n            \"year\",\n        ]\n    )\n    .to_pandas()\n    .set_index(\"year\")\n    .plot()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```\n<Axes: xlabel='year'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Polars_revised_files/figure-html/cell-40-output-2.png){width=583 height=429}\n:::\n:::\n\n\n## Pivot\n\nYou can also accomplish split-apply-combine tasks seamlessly using the pivot function. It's remarkably straightforward.\n\n::: {.cell tags='[]' execution_count=40}\n``` {.python .cell-code}\n(\n    df.with_columns(\n        pl.col(\"fuelType\").cast(pl.Utf8)\n    )  # conversion to str is needed for the next step\n    .filter(pl.col(\"fuelType\").is_in([\"Regular\", \"Premium\"]))\n    .pivot(values=\"city08\", index=\"make\", columns=\"fuelType\", aggregate_function=\"mean\")\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (126, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>Regular</th><th>Premium</th></tr><tr><td>cat</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td><td>17.142857</td><td>18.902439</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;PAS Inc - GMC&quot;</td><td>null</td><td>14.0</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n# Handling missing data\n\n## Getting missing value count per column  \n\nThe `null_count` function showcases the count of missing values in the dataframe. Remember, these are not the same as np.nans; it's important to be aware of this distinction. This functionality is akin to the pandas `df.isna().sum()` operation if you're familiar with pandas.\n\n::: {.cell tags='[]' execution_count=41}\n``` {.python .cell-code}\ndf.null_count()\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (1, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>drive</th><th>cylinders</th><th>displ</th><th>fuelType</th><th>mpgData</th><th>city08</th><th>highway08</th><th>comb08</th><th>year</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>1189</td><td>206</td><td>204</td><td>0</td><td>0</td><td>27</td><td>0</td><td>7</td><td>0</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Getting boolean array of missing values \n\nIf you ever need to manipulate a series based on its null values, you can also obtain a boolean mask using the `is_null` function. This can be really handy for targeted data manipulation.\n\n::: {.cell .column-margin tags='[]' execution_count=42}\n``` {.python .cell-code}\ndf.select(pl.col(\"city08\").is_null())\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>city08</th></tr><tr><td>bool</td></tr></thead><tbody><tr><td>false</td></tr><tr><td>&hellip;</td></tr><tr><td>false</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Filling missing values\n\nYou have a variety of options at your disposal for filling in missing values. Here's a list of some of the most common ones, although it's not an exhaustive rundown.\n\n### With literals\n\n::: {.cell tags='[]' execution_count=43}\n``` {.python .cell-code}\n(df.with_columns(pl.col(\"cylinders\").fill_null(pl.lit(2))))\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>drive</th><th>cylinders</th><th>displ</th><th>fuelType</th><th>mpgData</th><th>city08</th><th>highway08</th><th>comb08</th><th>year</th></tr><tr><td>cat</td><td>cat</td><td>cat</td><td>i8</td><td>f32</td><td>cat</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td><td>date</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td><td>&quot;Spider Veloce …</td><td>&quot;Rear-Wheel Dri…</td><td>4</td><td>2.0</td><td>&quot;Regular&quot;</td><td>true</td><td>19</td><td>25</td><td>21</td><td>1985-01-01</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Subaru&quot;</td><td>&quot;Legacy AWD Tur…</td><td>&quot;4-Wheel or All…</td><td>4</td><td>2.2</td><td>&quot;Premium&quot;</td><td>false</td><td>16</td><td>21</td><td>18</td><td>1993-01-01</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n::: {.cell tags='[]' execution_count=44}\n``` {.python .cell-code}\n(df.with_columns(pl.col(\"cylinders\").fill_null(strategy=\"zero\")))\n```\n\n::: {.cell-output .cell-output-display execution_count=44}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>drive</th><th>cylinders</th><th>displ</th><th>fuelType</th><th>mpgData</th><th>city08</th><th>highway08</th><th>comb08</th><th>year</th></tr><tr><td>cat</td><td>cat</td><td>cat</td><td>i8</td><td>f32</td><td>cat</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td><td>date</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td><td>&quot;Spider Veloce …</td><td>&quot;Rear-Wheel Dri…</td><td>4</td><td>2.0</td><td>&quot;Regular&quot;</td><td>true</td><td>19</td><td>25</td><td>21</td><td>1985-01-01</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Subaru&quot;</td><td>&quot;Legacy AWD Tur…</td><td>&quot;4-Wheel or All…</td><td>4</td><td>2.2</td><td>&quot;Premium&quot;</td><td>false</td><td>16</td><td>21</td><td>18</td><td>1993-01-01</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n::: {.cell tags='[]' execution_count=45}\n``` {.python .cell-code}\n(df.with_columns(pl.col(\"cylinders\").fill_null(strategy=\"forward\")))\n```\n\n::: {.cell-output .cell-output-display execution_count=45}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>drive</th><th>cylinders</th><th>displ</th><th>fuelType</th><th>mpgData</th><th>city08</th><th>highway08</th><th>comb08</th><th>year</th></tr><tr><td>cat</td><td>cat</td><td>cat</td><td>i8</td><td>f32</td><td>cat</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td><td>date</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td><td>&quot;Spider Veloce …</td><td>&quot;Rear-Wheel Dri…</td><td>4</td><td>2.0</td><td>&quot;Regular&quot;</td><td>true</td><td>19</td><td>25</td><td>21</td><td>1985-01-01</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Subaru&quot;</td><td>&quot;Legacy AWD Tur…</td><td>&quot;4-Wheel or All…</td><td>4</td><td>2.2</td><td>&quot;Premium&quot;</td><td>false</td><td>16</td><td>21</td><td>18</td><td>1993-01-01</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n### With an expression\n\nThis can be very useful for machine learning pipelines. When addressing missing values, you can set them to the mode, median, mean, or any other value that suits your needs.\n\n::: {.cell tags='[]' execution_count=46}\n``` {.python .cell-code}\n(df.with_columns(pl.col(\"cylinders\").fill_null(pl.col(\"cylinders\").mode())))\n```\n\n::: {.cell-output .cell-output-display execution_count=46}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>drive</th><th>cylinders</th><th>displ</th><th>fuelType</th><th>mpgData</th><th>city08</th><th>highway08</th><th>comb08</th><th>year</th></tr><tr><td>cat</td><td>cat</td><td>cat</td><td>i8</td><td>f32</td><td>cat</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td><td>date</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td><td>&quot;Spider Veloce …</td><td>&quot;Rear-Wheel Dri…</td><td>4</td><td>2.0</td><td>&quot;Regular&quot;</td><td>true</td><td>19</td><td>25</td><td>21</td><td>1985-01-01</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Subaru&quot;</td><td>&quot;Legacy AWD Tur…</td><td>&quot;4-Wheel or All…</td><td>4</td><td>2.2</td><td>&quot;Premium&quot;</td><td>false</td><td>16</td><td>21</td><td>18</td><td>1993-01-01</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n### Using the `over` function \n\nThe `over` function in Polars is used to perform window operations, akin to what you'd achieve with window functions in SQL or the `transform` function in pandas. This function enables you to compute aggregations over a specified window or range of rows defined by a window specification. It's perfect for tasks like calculating rolling averages, cumulative sums, and other operations that involve working with a specific subset of rows within the dataset.\n\nLet's begin by filtering the car makes to encompass only the top 5 car brands. Following that, we can utilize the `over` function to derive several statistics.\n\n::: {.cell tags='[]' execution_count=47}\n``` {.python .cell-code}\ntop5 = (\n    df.select(pl.col(\"make\"))\n    .to_series()\n    .value_counts()\n    .sort(by=\"counts\", descending=True)\n    .limit(3)\n    .select(pl.col(\"make\"))\n    .to_series()\n)\n\n(\n    df.filter(pl.col(\"make\").is_in(top5)).select(\n        \"make\",\n        \"model\",\n        pl.col(\"city08\").mean().over(\"make\").alias(\"avg_city_mpg_by_make\"),\n        pl.col(\"city08\").mean().over(\"model\").alias(\"avg_city_mpg_by_model\"),\n        pl.col(\"comb08\").mean().over([\"make\", \"model\"]).alias(\"avg_comb_mpg_by_model\"),\n    )\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=47}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (9_957, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>avg_city_mpg_by_make</th><th>avg_city_mpg_by_model</th><th>avg_comb_mpg_by_model</th></tr><tr><td>cat</td><td>cat</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Dodge&quot;</td><td>&quot;Charger&quot;</td><td>15.462253</td><td>18.197531</td><td>21.320988</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Dodge&quot;</td><td>&quot;B150/B250 Wago…</td><td>15.462253</td><td>11.654321</td><td>12.925926</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n# Other common operations\n\nIn the upcoming section, you'll discover a mix of handy operations that I've ended up using quite often. These don't exactly fit into the categories we've covered earlier, but they're still quite useful!\n\n## Operating on multiple columns and renaming them\n\nYou have the flexibility to conduct column operations and then easily rename them. Additionally, you can make use of the `prefix` and `suffix` functions to streamline your workflow. \n\n::: {.cell tags='[]' execution_count=48}\n``` {.python .cell-code}\n(df.with_columns((cs.numeric() * 2).prefix(\"changed_\")))\n```\n\n::: {.cell-output .cell-output-display execution_count=48}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>drive</th><th>cylinders</th><th>displ</th><th>fuelType</th><th>mpgData</th><th>city08</th><th>highway08</th><th>comb08</th><th>year</th><th>changed_cylinders</th><th>changed_displ</th><th>changed_city08</th><th>changed_highway08</th><th>changed_comb08</th></tr><tr><td>cat</td><td>cat</td><td>cat</td><td>i8</td><td>f32</td><td>cat</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td><td>date</td><td>i8</td><td>f32</td><td>i8</td><td>i8</td><td>i8</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td><td>&quot;Spider Veloce …</td><td>&quot;Rear-Wheel Dri…</td><td>4</td><td>2.0</td><td>&quot;Regular&quot;</td><td>true</td><td>19</td><td>25</td><td>21</td><td>1985-01-01</td><td>8</td><td>4.0</td><td>38</td><td>50</td><td>42</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Subaru&quot;</td><td>&quot;Legacy AWD Tur…</td><td>&quot;4-Wheel or All…</td><td>4</td><td>2.2</td><td>&quot;Premium&quot;</td><td>false</td><td>16</td><td>21</td><td>18</td><td>1993-01-01</td><td>8</td><td>4.4</td><td>32</td><td>42</td><td>36</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Count unique values\n\nAbsolutely, you can also count the unique values within a series in Polars, much like you would with the `unique` function in pandas. This can be really useful for understanding the distribution and diversity of data within a specific column.\n\n::: {.cell tags='[]' execution_count=49}\n``` {.python .cell-code}\ndf.select(pl.col(\"make\")).n_unique()\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```\n136\n```\n:::\n:::\n\n\n## Value_counts to get number of occurrences per item\n\n### On a single column\n\n::: {.cell .column-margin tags='[]' execution_count=50}\n``` {.python .cell-code}\n(df.select(pl.col(\"make\")).to_series().value_counts(sort=True))\n```\n\n::: {.cell-output .cell-output-display execution_count=50}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (136, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>counts</th></tr><tr><td>cat</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Chevrolet&quot;</td><td>4003</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Isis Imports L…</td><td>1</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n::: {.cell .column-margin tags='[]' execution_count=51}\n``` {.python .cell-code}\n(df.select(pl.col(\"make\")).groupby(\"make\").count().sort(by=\"count\", descending=True))\n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (136, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>count</th></tr><tr><td>cat</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Chevrolet&quot;</td><td>4003</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Panoz Auto-Dev…</td><td>1</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n### On multiple columns\n\nI noticed that Polars lacks the capability to perform value counts on multiple columns, unlike pandas' `value_counts` function which operates only on series. However, I've discovered that combining a `groupby` operation with a `count` function can effectively achieve the same outcome for multiple columns. It's all about finding alternative approaches that get the job done!\n\n::: {.cell .column-margin tags='[]' execution_count=52}\n``` {.python .cell-code}\n(\n    df.select(pl.col(\"make\", \"model\"))\n    .groupby([\"make\", \"model\"])\n    .count()\n    .sort(by=\"count\", descending=True)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=52}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (4_127, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>model</th><th>count</th></tr><tr><td>cat</td><td>cat</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Ford&quot;</td><td>&quot;F150 Pickup 2W…</td><td>214</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Mercedes-Benz&quot;</td><td>&quot;400SE&quot;</td><td>1</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n## Conditionals/ if-else statements\n\nIf you're looking to integrate conditional if-else statements into your Polars chain, you can make use of the `when`, `then`, and `otherwise` functions. However, keep in mind that a series of chained `when`, `then` statements should be interpreted as if, elif, ... elif, rather than if, if, ... if. In other words, the first condition that evaluates to True will be selected. It's crucial to understand this distinction when crafting your conditions.\n\n::: {.cell .column-margin tags='[]' execution_count=53}\n``` {.python .cell-code}\n(\n    df.select(\n        pl.col(\"make\"),\n        pl.when(pl.col(\"comb08\") < 15)\n        .then(\"bad\")\n        .when(pl.col(\"comb08\") < 30)\n        .then(\"good\")\n        .otherwise(\"very good\")\n        .alias(\"fuel_economy\"),\n    )\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=53}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (41_144, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>make</th><th>fuel_economy</th></tr><tr><td>cat</td><td>str</td></tr></thead><tbody><tr><td>&quot;Alfa Romeo&quot;</td><td>&quot;good&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Subaru&quot;</td><td>&quot;good&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nAlright, folks, that's it for this introduction to Polars. I know it wasn't exactly short, but I hope it was informative! I'll be adding more content to this article in the future, so stay tuned. Until then, happy coding 😎💻🔎\n\n# Document version\n\n| Version      | Date      | Comment          |\n|  :----:      | :----:    | :----:           |\n| 0.1          | 8/11/2023 | Document created |\n\n",
    "supporting": [
      "Polars_revised_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}