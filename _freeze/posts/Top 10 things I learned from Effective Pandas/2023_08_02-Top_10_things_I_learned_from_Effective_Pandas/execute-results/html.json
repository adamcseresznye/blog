{
  "hash": "81ff017a648450d21cfa3481f77b8f1b",
  "result": {
    "markdown": "---\ntitle: Top 10 things I learned from the book Effective Pandas by  Matt Harrison\nauthor: Adam Cseresznye\ndate: '2023-08-02'\ncategories:\n  - Pandas\ntoc: true\n---\n\n[Effective Pandas by Matt Harrison](https://store.metasnake.com/effective-pandas-book) is a guide to the Pandas library, a powerful Python tool for data manipulation and analysis. The book covers a wide range of topics, from basic data structures to advanced techniques for data cleaning, transformation, and visualization.\n\nI have found Effective Pandas to be a captivating and thought-provoking read. The book offers a genuinely unique take on data wrangling, putting a great emphasis on the utility of *chaining methods* and utilizing the *lambda function*. I have found these ideas to be so useful and practical that I have revisited the book multiple times just to make sure I keep them fresh in my memory. I must have read the book from back to back at least 3-4 times.\n\nIn this article, I will share the top 10 (+1) things I learned from Effective Pandas. These are the concepts and techniques that I found to be the most useful and practical.\n\nWe will use the [Real World Smartphone's Dataset](https://www.kaggle.com/datasets/abhijitdahatonde/real-world-smartphones-dataset?select=smartphones.csv) by Abhijit Dahatonde from Kaggle. Let's get to it.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_columns', None)\n```\n:::\n\n\n# Load the dataset\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndf=pd.read_csv('smartphones.csv')\n# some info about the dataframe, such as dimensions and dtypes of columns\ndf.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 980 entries, 0 to 979\nData columns (total 22 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   brand_name                 980 non-null    object \n 1   model                      980 non-null    object \n 2   price                      980 non-null    int64  \n 3   avg_rating                 879 non-null    float64\n 4   5G_or_not                  980 non-null    int64  \n 5   processor_brand            960 non-null    object \n 6   num_cores                  974 non-null    float64\n 7   processor_speed            938 non-null    float64\n 8   battery_capacity           969 non-null    float64\n 9   fast_charging_available    980 non-null    int64  \n 10  fast_charging              769 non-null    float64\n 11  ram_capacity               980 non-null    int64  \n 12  internal_memory            980 non-null    int64  \n 13  screen_size                980 non-null    float64\n 14  refresh_rate               980 non-null    int64  \n 15  num_rear_cameras           980 non-null    int64  \n 16  os                         966 non-null    object \n 17  primary_camera_rear        980 non-null    float64\n 18  primary_camera_front       975 non-null    float64\n 19  extended_memory_available  980 non-null    int64  \n 20  resolution_height          980 non-null    int64  \n 21  resolution_width           980 non-null    int64  \ndtypes: float64(8), int64(10), object(4)\nmemory usage: 168.6+ KB\n```\n:::\n:::\n\n\n# Tip #1: Use <code>pd.assign</code> more extensively\n\nThe <code>pd.assign</code> method in Pandas is a very powerful tool that can be used to create new columns, modify existing columns, or both. It is a very versatile method that can be used in a variety of ways.\n\nOne of the most important benefits of using the assign method is that it can be incorporated into method chaining. This means that you can chain multiple assign methods together to create a more concise and readable code. Another benefit of using the assign method is that it completely sidesteps the infamous <code>SettingWithCopyWarning</code>. This warning is often triggered when you try to modify an existing column in a DataFrame. However, the assign method creates a new DataFrame, so there is no need to worry about this warning.\n\n**Problem statement:** Let's say we would like to capitalize the brand names located in the <code>brand_name column</code> as well as calculate the Pixels Per Inch (PPI). PPI can be calculated following the equation described by the [Pixel density](https://en.wikipedia.org/wiki/Pixel_density) page on Wikipedia.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n(df\n .assign(brand_name=lambda df: df.brand_name.str.capitalize(), # capitalizes the brand names \n         PPI=lambda df: (np.sqrt(np.square(df.resolution_height) + np.square(df.resolution_width))\n                         .div(df.screen_size)\n                         .round(1)\n                        )\n        )\n .loc[:, ['brand_name','model','PPI']]\n .sort_values(by='PPI',ascending=False)\n .head(5)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brand_name</th>\n      <th>model</th>\n      <th>PPI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>689</th>\n      <td>Sony</td>\n      <td>Sony Xperia 1 IV (12GB RAM + 512GB)</td>\n      <td>642.6</td>\n    </tr>\n    <tr>\n      <th>696</th>\n      <td>Sony</td>\n      <td>Sony Xperia Pro-I</td>\n      <td>642.6</td>\n    </tr>\n    <tr>\n      <th>688</th>\n      <td>Sony</td>\n      <td>Sony Xperia 1 II</td>\n      <td>642.6</td>\n    </tr>\n    <tr>\n      <th>655</th>\n      <td>Samsung</td>\n      <td>Samsung Galaxy S20</td>\n      <td>566.0</td>\n    </tr>\n    <tr>\n      <th>656</th>\n      <td>Samsung</td>\n      <td>Samsung Galaxy S20 5G</td>\n      <td>566.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n# Tip #2: Simplify the management of multiple if-else conditions using <code>np.select</code>\n\nIf our goal is to incorporate if-else logic seamlessly into our code, we can effortlessly achieve this using either <code>pd.mask</code> or <code>pd.where</code>. Yet, what approach should we adopt when we need to evaluate multiple conditions instead of just two? In such situations, we have two options: we can either employ successive <code>pd.mask</code> or <code>pd.where</code> calls, or we can take advantage of the <code>np.select</code> function as an alternative solution.\n\n**Problem statement:** We want to identify the top 3 and top 5 most popular processor brands in smartphones. To do this, we will first create two lists, one for the top 3 brands and one for the top 5 brands. Any processor brand that is not in either of these lists will be categorized as \"Other\".\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Let's create the two lists that contain the top3 and top5 brand names\ntop3=df.processor_brand.value_counts().head(3).index\ntop5=df.processor_brand.value_counts().head(5).index\nprint(f'Top 3 most popular processors: {top3.tolist()}')\nprint(f'Top 5 most popular processors: {top5.tolist()}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTop 3 most popular processors: ['snapdragon', 'helio', 'dimensity']\nTop 5 most popular processors: ['snapdragon', 'helio', 'dimensity', 'exynos', 'bionic']\n```\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n'''\nHere's an example that employs two successive pd.where calls:\nIn the first pd.where call, it checks whether the brand is in the top 3; if not, it assigns the label \"Top5\" to it.\nThen, in the second call, it checks if the value is in the top 5; if not, it appends the category \"Other\".\nAs you can see, the logic can become intricate and difficult to grasp, especially when dealing with numerous conditions, \nmaking the code cumbersome and hard to manage.\n'''\n(df\n .assign(frequency=lambda df: df.processor_brand\n         .where(df.processor_brand.isin(top3), other = 'Top5')\n         .where(df.processor_brand.isin(top5), other = 'Other')\n        )\n .loc[:, 'frequency']\n .value_counts()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\nsnapdragon    413\nhelio         201\ndimensity     177\nTop5           95\nOther          94\nName: frequency, dtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n'''\n Now Let's see np.select!\n It simplifies the process significantly. By providing a list of conditions we want to evaluate and their \n corresponding values if the condition evaluates to True, we can handle multiple conditions effortlessly. \n Additionally, we can specify a default value if none of the conditions evaluates to True, making the code \n much more straightforward and easier to manage. \n'''\n(df\n .assign(frequency=lambda df: np.select(condlist=[df.processor_brand.isin(top3), df.processor_brand.isin(top5)],\n                                        choicelist=[df.processor_brand,'Top5'],\n                                        default='Other'\n                                       )\n        )\n .loc[:, 'frequency']\n .value_counts()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nsnapdragon    413\nhelio         201\ndimensity     177\nTop5           95\nOther          94\nName: frequency, dtype: int64\n```\n:::\n:::\n\n\n# Tip #3 Filter rows or columns with the combination of <code>pd.loc</code> and <code>lambda</code>\n\nSome experienced Pandas users might consider the following concept trivial, but it was an eye-opener for me after reading the book. It turns out that combining <code>pd.loc</code> and <code>lambda</code> (or any custom functions) allows us to filter both rows and columns, depending on our specific needs.\n\n**Problem statement:** We are interested in identifying phones with a battery capacity greater than 5000mAh.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n(df\n .loc[lambda df: df.battery_capacity.gt(5000),['model', 'battery_capacity']] # here we use pd.gt() to select values greater than 5000\n .sort_values(by='battery_capacity')\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>battery_capacity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>70</th>\n      <td>Google Pixel 6 Pro (12GB RAM + 256GB)</td>\n      <td>5003.0</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>Google Pixel 6 Pro</td>\n      <td>5003.0</td>\n    </tr>\n    <tr>\n      <th>977</th>\n      <td>Xiaomi Redmi Note 9 Pro Max</td>\n      <td>5020.0</td>\n    </tr>\n    <tr>\n      <th>922</th>\n      <td>Xiaomi Redmi Note 10 Lite</td>\n      <td>5020.0</td>\n    </tr>\n    <tr>\n      <th>923</th>\n      <td>Xiaomi Redmi Note 10 Lite (4GB RAM + 128GB)</td>\n      <td>5020.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>624</th>\n      <td>Samsung Galaxy F63</td>\n      <td>7000.0</td>\n    </tr>\n    <tr>\n      <th>411</th>\n      <td>Oukitel WP9</td>\n      <td>8000.0</td>\n    </tr>\n    <tr>\n      <th>410</th>\n      <td>Oukitel WP21</td>\n      <td>9800.0</td>\n    </tr>\n    <tr>\n      <th>409</th>\n      <td>Oukitel WP19</td>\n      <td>21000.0</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>Doogee V Max</td>\n      <td>22000.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>113 rows √ó 2 columns</p>\n</div>\n```\n:::\n:::\n\n\n# Tip #4 Rename multiple columns effortlessly with <code>rename</code> and <code>replace</code>\n\nOK. This is a big one for me. I used this one multiple times already. The title pretty much says it all. Let's say our column names contain spaces, which makes column selection by attribute access pretty much impossible.  Now, what do we do?\nWell...Let's see.\n\n**Problem statement:** We would like to remove all the underscores from our column names.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ndf.columns # original column names for reference\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\nIndex(['brand_name', 'model', 'price', 'avg_rating', '5G_or_not',\n       'processor_brand', 'num_cores', 'processor_speed', 'battery_capacity',\n       'fast_charging_available', 'fast_charging', 'ram_capacity',\n       'internal_memory', 'screen_size', 'refresh_rate', 'num_rear_cameras',\n       'os', 'primary_camera_rear', 'primary_camera_front',\n       'extended_memory_available', 'resolution_height', 'resolution_width'],\n      dtype='object')\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# column names after replacing underscores\n(df\n .rename(columns = lambda x: x.replace('_', ''))\n .columns\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\nIndex(['brandname', 'model', 'price', 'avgrating', '5Gornot', 'processorbrand',\n       'numcores', 'processorspeed', 'batterycapacity',\n       'fastchargingavailable', 'fastcharging', 'ramcapacity',\n       'internalmemory', 'screensize', 'refreshrate', 'numrearcameras', 'os',\n       'primarycamerarear', 'primarycamerafront', 'extendedmemoryavailable',\n       'resolutionheight', 'resolutionwidth'],\n      dtype='object')\n```\n:::\n:::\n\n\n# Tip #5: Use <code>pd.clip</code> to easily remove outliers\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n# First, we'll identify the phone brands with the most number of handsets present in our dataset.\"\ntop10_brand_names = (df\n                     .brand_name\n                     .value_counts()\n                     .head(10)\n                     .index\n                     .tolist()\n                    )\nprint(top10_brand_names)\n\n# Then we will sort them based on median price\ntop10_brand_names_ordered = (df\n                             .loc[lambda x: x.brand_name.isin(top10_brand_names),['brand_name', 'price']]\n                             .groupby('brand_name')\n                             .median()\n                             .sort_values(by='price')\n                             .index\n                             .to_list()\n                            )\nprint(top10_brand_names_ordered)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['xiaomi', 'samsung', 'vivo', 'realme', 'oppo', 'motorola', 'apple', 'oneplus', 'poco', 'tecno']\n['tecno', 'poco', 'realme', 'xiaomi', 'motorola', 'vivo', 'oppo', 'samsung', 'oneplus', 'apple']\n```\n:::\n:::\n\n\n::: {.cell .column-page tags='[]' execution_count=11}\n``` {.python .cell-code}\nfig, axs = plt.subplots(1,2, figsize=(10,5))\n\n# For reference, this is what our box plot looks if we leave in the outlier values\n(df\n .loc[lambda x: x.brand_name.isin(top10_brand_names),['brand_name', 'price']] # filter rows based on top10_brand_names and select columns\n .pivot(columns='brand_name',values='price') # pivot to get the brand names on the x axis later on\n .loc[:, top10_brand_names_ordered] # order the columns based on median price\n .plot\n .box(title='Top 10 most popular smartphone brands \\n -outlier values included-', \n      rot=90,\n      ax=axs[0]\n     )\n)\n\n(df\n .loc[lambda x: x['brand_name'].isin(top10_brand_names), ['brand_name', 'price']]\n .pivot(columns='brand_name', values='price')\n .loc[:, top10_brand_names_ordered]\n .pipe(lambda df: df.assign(**{col : df[col].clip(lower=df[col].quantile(0.05), # this is called dictionary unpacking\n                                                  upper=df[col].quantile(0.95))\n                              for col in df.columns}))\n .plot\n .box(title='Top 10 most popular smartphone brands \\n -only values between 5th and 95th percentiles included-',\n      rot=90,\n      ax=axs[1]\n     )\n)\naxs[0].set(ylabel='Price in local currency')\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](2023_08_02-Top_10_things_I_learned_from_Effective_Pandas_files/figure-html/cell-12-output-1.png){width=984 height=471}\n:::\n:::\n\n\n# Tip #6: Find corrupted entries with <code>str.extract</code>\n\nHow often have you encountered the situation where, for some reason, a column that is expected to only contain numerical values displays <code>object</code> as its <code>dtype</code>? This often indicates the presence of some string values mixed within the column. It would be beneficial to promptly identify all the erroneous values, correct them, and proceed with our analysis smoothly. Let's explore what we can do in such scenarios.\n\n**Problem statement:** We would like to identify any cells in a specific column that contain non-numerical values.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ndf_bad_values = df.copy(deep=True) # let's prepare a copy of the original dataframe \n\n# let's modify some of the values in the price column randomly:\ndf_bad_values.loc[np.random.randint(0, high=df_bad_values.shape[0], size=10), 'price'] = '.'\ndf_bad_values.loc[np.random.randint(0, high=df_bad_values.shape[0], size=10), 'price'] = '-'\ndf_bad_values.loc[np.random.randint(0, high=df_bad_values.shape[0], size=10), 'price'] = '*'\ndf_bad_values.info() # the modified dataframe's price column now returns object as dtype\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 980 entries, 0 to 979\nData columns (total 22 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   brand_name                 980 non-null    object \n 1   model                      980 non-null    object \n 2   price                      980 non-null    object \n 3   avg_rating                 879 non-null    float64\n 4   5G_or_not                  980 non-null    int64  \n 5   processor_brand            960 non-null    object \n 6   num_cores                  974 non-null    float64\n 7   processor_speed            938 non-null    float64\n 8   battery_capacity           969 non-null    float64\n 9   fast_charging_available    980 non-null    int64  \n 10  fast_charging              769 non-null    float64\n 11  ram_capacity               980 non-null    int64  \n 12  internal_memory            980 non-null    int64  \n 13  screen_size                980 non-null    float64\n 14  refresh_rate               980 non-null    int64  \n 15  num_rear_cameras           980 non-null    int64  \n 16  os                         966 non-null    object \n 17  primary_camera_rear        980 non-null    float64\n 18  primary_camera_front       975 non-null    float64\n 19  extended_memory_available  980 non-null    int64  \n 20  resolution_height          980 non-null    int64  \n 21  resolution_width           980 non-null    int64  \ndtypes: float64(8), int64(9), object(5)\nmemory usage: 168.6+ KB\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n# let's find the corrupted values easily:\n(df_bad_values\n .price\n .str.extract(r'([^a-zA-Z])') # returns NON-matching alphabetical characters\n .value_counts()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\n*    10\n-    10\n.    10\ndtype: int64\n```\n:::\n:::\n\n\n# Tip #7: Sort values based on the <code>key</code> parameter\n\nThe <code>pd.sort_values</code> function surprised me with its versatility. Previously, I had only used its <code>by</code>, <code>axis</code>, and <code>ascending</code> parameters for sorting. However, Matt's book introduced me to its <code>key</code> parameter, which allows us to apply any function to sort the values. The only constraint is that the function must return a <code>Series</code>. \n\n**Problem statement:** For whatever reason, we would like to sort the phone model names in ascending order based on their second letter.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n(df\n .iloc[:, 1:3]\n .sort_values(by='model',\n              key = lambda x: x.str[1],\n              ascending = True\n             )\n .head(10)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>55</th>\n      <td>CAT S22 Flip</td>\n      <td>14999</td>\n    </tr>\n    <tr>\n      <th>697</th>\n      <td>TCL Ion X</td>\n      <td>8990</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>LG V60 ThinQ</td>\n      <td>79990</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>LG Velvet 5G</td>\n      <td>54999</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>LG Wing 5G</td>\n      <td>54999</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>iKall Z19 Pro</td>\n      <td>8099</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>iKall Z19</td>\n      <td>7999</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>iKall Z18</td>\n      <td>6799</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>BLU F91 5G</td>\n      <td>14990</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>POCO C31 (4GB RAM + 64GB)</td>\n      <td>7499</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n# Tip #8: Reference an existing variable inside <code>pd.query</code> with @\n\nThis resembles Tip #4, as it's a technique I frequently use. Since reading Matt's book, I have started using <code>pd.query</code> extensively to filter rows based on values, instead of relying on <code>.loc</code> or <code>.iloc</code>. In case you choose to adopt <code>pd.query</code> as well, it's essential to be aware of its capability to use \"@\" to reference variables in the environment. This feature enhances its flexibility and makes it even more convenient to apply in various data filtering scenarios.\n\n**Problem statement:** Our objective is to identify phones that meet three specific criteria: being priced below the average market price, having more processor cores than the average, and possessing a battery capacity greater than the average.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\naverage_price=df.price.mean()\naverage_cores=df.num_cores.mean()\naverage_battery=df.battery_capacity.mean()\n\n(df\n .query(\"(price <= @average_price) and (num_cores >= @average_cores) and (battery_capacity >= @average_battery)\")\n .iloc[:,:3]\n .sort_values(by='price')\n .head()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brand_name</th>\n      <th>model</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>498</th>\n      <td>realme</td>\n      <td>Realme C30</td>\n      <td>5299</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>itel</td>\n      <td>itel Vision 3 (2GB RAM + 32GB)</td>\n      <td>5785</td>\n    </tr>\n    <tr>\n      <th>202</th>\n      <td>micromax</td>\n      <td>Micromax IN 2C</td>\n      <td>5999</td>\n    </tr>\n    <tr>\n      <th>729</th>\n      <td>tecno</td>\n      <td>Tecno Spark Go 2022</td>\n      <td>6249</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>realme</td>\n      <td>Realme C30 (3GB RAM + 32GB)</td>\n      <td>6299</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n# Tip #9: Gain more insights by using <code>style.background_gradient</code>\n\nBeing a visual creature, I often struggle to comprehend data quickly just by examining the raw table alone. Fortunately, with the help of <code>style.background_gradient</code>, similar to the <code>heatmap</code> function in the <code>seaborn</code> library, we can represent cells, in terms of color gradient, based on their values. This enables us to identify trends and patterns in our data swiftly, making data analysis more intuitive and insightful.\n\n**Problem statement:** Our goal is to identify the overall trends related to key descriptors found among the Top 10 smartphone brands, aiming to determine which brand offers the most value for our money. \n\n::: {.cell .column-page execution_count=16}\n``` {.python .cell-code}\n(df\n .query(\"brand_name.isin(@top10_brand_names_ordered)\") # filter rows based on top10 brands\n .groupby(['brand_name',])\n [['avg_rating', 'processor_speed', 'ram_capacity', \n   'screen_size', 'battery_capacity', 'price']]\n .mean()\n .sort_values(by='avg_rating')\n .transpose()\n .rename(columns=str.capitalize) # capitalize brand names\n .style\n .set_caption(\"Key descriptors of the Top 10 smartphone brands\")\n .format(precision=1)\n .background_gradient(cmap = 'vlag', axis = 1)\n .set_table_styles([\n    {'selector': 'td', 'props': 'text-align: center;'},\n     {'selector': 'caption','props': 'font-size:1.5em; font-weight:bold;'}\n     ,]\n )\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```{=html}\n<style type=\"text/css\">\n#T_39fb7 td {\n  text-align: center;\n}\n#T_39fb7 caption {\n  font-size: 1.5em;\n  font-weight: bold;\n}\n#T_39fb7_row0_col0, #T_39fb7_row1_col0, #T_39fb7_row2_col2, #T_39fb7_row3_col2, #T_39fb7_row4_col2, #T_39fb7_row5_col0 {\n  background-color: #2369bd;\n  color: #f1f1f1;\n}\n#T_39fb7_row0_col1 {\n  background-color: #b8c3d5;\n  color: #000000;\n}\n#T_39fb7_row0_col2, #T_39fb7_row2_col7 {\n  background-color: #cad0dd;\n  color: #000000;\n}\n#T_39fb7_row0_col3 {\n  background-color: #dcdee6;\n  color: #000000;\n}\n#T_39fb7_row0_col4, #T_39fb7_row0_col5 {\n  background-color: #efd8d6;\n  color: #000000;\n}\n#T_39fb7_row0_col6 {\n  background-color: #eed7d5;\n  color: #000000;\n}\n#T_39fb7_row0_col7 {\n  background-color: #edd5d3;\n  color: #000000;\n}\n#T_39fb7_row0_col8, #T_39fb7_row3_col5 {\n  background-color: #d39794;\n  color: #f1f1f1;\n}\n#T_39fb7_row0_col9, #T_39fb7_row1_col2, #T_39fb7_row2_col9, #T_39fb7_row3_col0, #T_39fb7_row4_col0, #T_39fb7_row5_col2 {\n  background-color: #a9373b;\n  color: #f1f1f1;\n}\n#T_39fb7_row1_col1, #T_39fb7_row5_col3 {\n  background-color: #7192c0;\n  color: #f1f1f1;\n}\n#T_39fb7_row1_col3 {\n  background-color: #97abc9;\n  color: #f1f1f1;\n}\n#T_39fb7_row1_col4 {\n  background-color: #bfc8d8;\n  color: #000000;\n}\n#T_39fb7_row1_col5 {\n  background-color: #adbbd1;\n  color: #000000;\n}\n#T_39fb7_row1_col6 {\n  background-color: #c0c9d9;\n  color: #000000;\n}\n#T_39fb7_row1_col7 {\n  background-color: #bac4d6;\n  color: #000000;\n}\n#T_39fb7_row1_col8 {\n  background-color: #bbc5d7;\n  color: #000000;\n}\n#T_39fb7_row1_col9 {\n  background-color: #f2e0df;\n  color: #000000;\n}\n#T_39fb7_row2_col0, #T_39fb7_row5_col1 {\n  background-color: #3b73bc;\n  color: #f1f1f1;\n}\n#T_39fb7_row2_col1 {\n  background-color: #678bbe;\n  color: #f1f1f1;\n}\n#T_39fb7_row2_col3 {\n  background-color: #f7f4f4;\n  color: #000000;\n}\n#T_39fb7_row2_col4, #T_39fb7_row5_col5 {\n  background-color: #a5b5ce;\n  color: #000000;\n}\n#T_39fb7_row2_col5 {\n  background-color: #e2e3ea;\n  color: #000000;\n}\n#T_39fb7_row2_col6, #T_39fb7_row3_col3 {\n  background-color: #d49a97;\n  color: #f1f1f1;\n}\n#T_39fb7_row2_col8 {\n  background-color: #aab8d0;\n  color: #000000;\n}\n#T_39fb7_row3_col1 {\n  background-color: #d9a6a4;\n  color: #000000;\n}\n#T_39fb7_row3_col4, #T_39fb7_row3_col7 {\n  background-color: #c47371;\n  color: #f1f1f1;\n}\n#T_39fb7_row3_col6, #T_39fb7_row4_col7 {\n  background-color: #cd8885;\n  color: #f1f1f1;\n}\n#T_39fb7_row3_col8 {\n  background-color: #cc8784;\n  color: #f1f1f1;\n}\n#T_39fb7_row3_col9 {\n  background-color: #c97f7d;\n  color: #f1f1f1;\n}\n#T_39fb7_row4_col1 {\n  background-color: #d29491;\n  color: #f1f1f1;\n}\n#T_39fb7_row4_col3 {\n  background-color: #e3bfbd;\n  color: #000000;\n}\n#T_39fb7_row4_col4 {\n  background-color: #c87c7a;\n  color: #f1f1f1;\n}\n#T_39fb7_row4_col5 {\n  background-color: #d1918e;\n  color: #f1f1f1;\n}\n#T_39fb7_row4_col6 {\n  background-color: #e7c7c5;\n  color: #000000;\n}\n#T_39fb7_row4_col8 {\n  background-color: #d59c99;\n  color: #f1f1f1;\n}\n#T_39fb7_row4_col9 {\n  background-color: #deb2b0;\n  color: #000000;\n}\n#T_39fb7_row5_col4 {\n  background-color: #4276bc;\n  color: #f1f1f1;\n}\n#T_39fb7_row5_col6 {\n  background-color: #809bc3;\n  color: #f1f1f1;\n}\n#T_39fb7_row5_col7 {\n  background-color: #7896c1;\n  color: #f1f1f1;\n}\n#T_39fb7_row5_col8 {\n  background-color: #6489be;\n  color: #f1f1f1;\n}\n#T_39fb7_row5_col9 {\n  background-color: #a0b1cc;\n  color: #000000;\n}\n</style>\n<table id=\"T_39fb7\">\n  <caption>Key descriptors of the Top 10 smartphone brands</caption>\n  <thead>\n    <tr>\n      <th class=\"index_name level0\" >brand_name</th>\n      <th id=\"T_39fb7_level0_col0\" class=\"col_heading level0 col0\" >Tecno</th>\n      <th id=\"T_39fb7_level0_col1\" class=\"col_heading level0 col1\" >Realme</th>\n      <th id=\"T_39fb7_level0_col2\" class=\"col_heading level0 col2\" >Apple</th>\n      <th id=\"T_39fb7_level0_col3\" class=\"col_heading level0 col3\" >Vivo</th>\n      <th id=\"T_39fb7_level0_col4\" class=\"col_heading level0 col4\" >Poco</th>\n      <th id=\"T_39fb7_level0_col5\" class=\"col_heading level0 col5\" >Samsung</th>\n      <th id=\"T_39fb7_level0_col6\" class=\"col_heading level0 col6\" >Oppo</th>\n      <th id=\"T_39fb7_level0_col7\" class=\"col_heading level0 col7\" >Xiaomi</th>\n      <th id=\"T_39fb7_level0_col8\" class=\"col_heading level0 col8\" >Motorola</th>\n      <th id=\"T_39fb7_level0_col9\" class=\"col_heading level0 col9\" >Oneplus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_39fb7_level0_row0\" class=\"row_heading level0 row0\" >avg_rating</th>\n      <td id=\"T_39fb7_row0_col0\" class=\"data row0 col0\" >7.4</td>\n      <td id=\"T_39fb7_row0_col1\" class=\"data row0 col1\" >7.6</td>\n      <td id=\"T_39fb7_row0_col2\" class=\"data row0 col2\" >7.7</td>\n      <td id=\"T_39fb7_row0_col3\" class=\"data row0 col3\" >7.7</td>\n      <td id=\"T_39fb7_row0_col4\" class=\"data row0 col4\" >7.9</td>\n      <td id=\"T_39fb7_row0_col5\" class=\"data row0 col5\" >7.9</td>\n      <td id=\"T_39fb7_row0_col6\" class=\"data row0 col6\" >7.9</td>\n      <td id=\"T_39fb7_row0_col7\" class=\"data row0 col7\" >7.9</td>\n      <td id=\"T_39fb7_row0_col8\" class=\"data row0 col8\" >8.0</td>\n      <td id=\"T_39fb7_row0_col9\" class=\"data row0 col9\" >8.2</td>\n    </tr>\n    <tr>\n      <th id=\"T_39fb7_level0_row1\" class=\"row_heading level0 row1\" >processor_speed</th>\n      <td id=\"T_39fb7_row1_col0\" class=\"data row1 col0\" >2.1</td>\n      <td id=\"T_39fb7_row1_col1\" class=\"data row1 col1\" >2.3</td>\n      <td id=\"T_39fb7_row1_col2\" class=\"data row1 col2\" >3.1</td>\n      <td id=\"T_39fb7_row1_col3\" class=\"data row1 col3\" >2.4</td>\n      <td id=\"T_39fb7_row1_col4\" class=\"data row1 col4\" >2.5</td>\n      <td id=\"T_39fb7_row1_col5\" class=\"data row1 col5\" >2.4</td>\n      <td id=\"T_39fb7_row1_col6\" class=\"data row1 col6\" >2.5</td>\n      <td id=\"T_39fb7_row1_col7\" class=\"data row1 col7\" >2.4</td>\n      <td id=\"T_39fb7_row1_col8\" class=\"data row1 col8\" >2.5</td>\n      <td id=\"T_39fb7_row1_col9\" class=\"data row1 col9\" >2.7</td>\n    </tr>\n    <tr>\n      <th id=\"T_39fb7_level0_row2\" class=\"row_heading level0 row2\" >ram_capacity</th>\n      <td id=\"T_39fb7_row2_col0\" class=\"data row2 col0\" >5.4</td>\n      <td id=\"T_39fb7_row2_col1\" class=\"data row2 col1\" >5.7</td>\n      <td id=\"T_39fb7_row2_col2\" class=\"data row2 col2\" >5.3</td>\n      <td id=\"T_39fb7_row2_col3\" class=\"data row2 col3\" >6.7</td>\n      <td id=\"T_39fb7_row2_col4\" class=\"data row2 col4\" >6.1</td>\n      <td id=\"T_39fb7_row2_col5\" class=\"data row2 col5\" >6.5</td>\n      <td id=\"T_39fb7_row2_col6\" class=\"data row2 col6\" >7.5</td>\n      <td id=\"T_39fb7_row2_col7\" class=\"data row2 col7\" >6.4</td>\n      <td id=\"T_39fb7_row2_col8\" class=\"data row2 col8\" >6.1</td>\n      <td id=\"T_39fb7_row2_col9\" class=\"data row2 col9\" >8.2</td>\n    </tr>\n    <tr>\n      <th id=\"T_39fb7_level0_row3\" class=\"row_heading level0 row3\" >screen_size</th>\n      <td id=\"T_39fb7_row3_col0\" class=\"data row3 col0\" >6.7</td>\n      <td id=\"T_39fb7_row3_col1\" class=\"data row3 col1\" >6.5</td>\n      <td id=\"T_39fb7_row3_col2\" class=\"data row3 col2\" >6.1</td>\n      <td id=\"T_39fb7_row3_col3\" class=\"data row3 col3\" >6.5</td>\n      <td id=\"T_39fb7_row3_col4\" class=\"data row3 col4\" >6.6</td>\n      <td id=\"T_39fb7_row3_col5\" class=\"data row3 col5\" >6.6</td>\n      <td id=\"T_39fb7_row3_col6\" class=\"data row3 col6\" >6.6</td>\n      <td id=\"T_39fb7_row3_col7\" class=\"data row3 col7\" >6.6</td>\n      <td id=\"T_39fb7_row3_col8\" class=\"data row3 col8\" >6.6</td>\n      <td id=\"T_39fb7_row3_col9\" class=\"data row3 col9\" >6.6</td>\n    </tr>\n    <tr>\n      <th id=\"T_39fb7_level0_row4\" class=\"row_heading level0 row4\" >battery_capacity</th>\n      <td id=\"T_39fb7_row4_col0\" class=\"data row4 col0\" >5333.9</td>\n      <td id=\"T_39fb7_row4_col1\" class=\"data row4 col1\" >4903.1</td>\n      <td id=\"T_39fb7_row4_col2\" class=\"data row4 col2\" >3527.2</td>\n      <td id=\"T_39fb7_row4_col3\" class=\"data row4 col3\" >4703.7</td>\n      <td id=\"T_39fb7_row4_col4\" class=\"data row4 col4\" >5009.4</td>\n      <td id=\"T_39fb7_row4_col5\" class=\"data row4 col5\" >4917.4</td>\n      <td id=\"T_39fb7_row4_col6\" class=\"data row4 col6\" >4667.2</td>\n      <td id=\"T_39fb7_row4_col7\" class=\"data row4 col7\" >4957.6</td>\n      <td id=\"T_39fb7_row4_col8\" class=\"data row4 col8\" >4863.1</td>\n      <td id=\"T_39fb7_row4_col9\" class=\"data row4 col9\" >4759.5</td>\n    </tr>\n    <tr>\n      <th id=\"T_39fb7_level0_row5\" class=\"row_heading level0 row5\" >price</th>\n      <td id=\"T_39fb7_row5_col0\" class=\"data row5 col0\" >14545.4</td>\n      <td id=\"T_39fb7_row5_col1\" class=\"data row5 col1\" >17461.4</td>\n      <td id=\"T_39fb7_row5_col2\" class=\"data row5 col2\" >95966.5</td>\n      <td id=\"T_39fb7_row5_col3\" class=\"data row5 col3\" >26782.4</td>\n      <td id=\"T_39fb7_row5_col4\" class=\"data row5 col4\" >18479.2</td>\n      <td id=\"T_39fb7_row5_col5\" class=\"data row5 col5\" >36843.0</td>\n      <td id=\"T_39fb7_row5_col6\" class=\"data row5 col6\" >29650.0</td>\n      <td id=\"T_39fb7_row5_col7\" class=\"data row5 col7\" >27961.1</td>\n      <td id=\"T_39fb7_row5_col8\" class=\"data row5 col8\" >24099.9</td>\n      <td id=\"T_39fb7_row5_col9\" class=\"data row5 col9\" >35858.6</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\n# Tip #10: Use <code>pd.pipe</code> to include any functions in our chain\n\nOne of the most valuable lessons I learned from Effective Pandas is the importance of arranging my code in a chain. Although it may feel somewhat restrictive at first, once you overcome the initial hurdles, you'll realize that your code becomes more readable and easier to understand. The need to invent unique names for temporary variables is completely eliminated, making coding a much happier experience.  \n  \nIn the chaining world, you often find yourself wanting to use various functions that are not explicitly designed for chaining. However, there's good news! You can still achieve this. The  <code>pd.pipe</code> function comes to the rescue, allowing you to use any function as long as it returns a Series or DataFrame. It's a flexible solution that empowers you to seamlessly integrate different functions into your chaining workflow, making your data manipulation more efficient and enjoyable.\n\n**Problem statement:** We aim to visualize the impact of RAM capacity on user satisfaction. To achieve this, we will utilize the <code>sns.lmplot</code> function, which plots the data and corresponding regression models for the Top 5 phone brands. \n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\ntop5_brand_names_ordered = df.brand_name.value_counts().head().index\n\nwith sns.axes_style(\"darkgrid\"):\n    g = (df\n         .query(\"brand_name.isin(@top5_brand_names_ordered)\") # filter rows based on top10 brands\n         [['brand_name', 'avg_rating', 'ram_capacity']]\n         .assign(brand_name=lambda df: df.brand_name.str.capitalize())\n         .rename(columns={'brand_name':'Brand name'})\n         .pipe(lambda df: sns.lmplot(data=df,\n                                     x='ram_capacity',\n                                     y='avg_rating',\n                                     hue='Brand name',\n                                     # height=4,\n                                     # aspect=1.2\n                                    )\n              )\n        )\n\n    g.set(title='Customer satisfaction correlates with RAM capacity', \n          xlabel='RAM capacity',\n          ylabel='User rating'\n         )\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](2023_08_02-Top_10_things_I_learned_from_Effective_Pandas_files/figure-html/cell-18-output-1.png){width=584 height=470}\n:::\n:::\n\n\n# Tip #10 + 1: Use the \"margin\" parameter of <code>pd.crosstab</code> to easily calculate row/column subtotals\n\nDespite primarily using the pandas <code>groupby</code> function for data aggregation, the <code>pd.crosstab</code> function has an enticing feature: the <code>margin</code> parameter. This option enables us to effortlessly calculate subtotals across rows and columns. Moreover, by normalizing our data, we can gain even more intuition about the questions we want to answer.\n\n**Problem statement:** Our objective is to evaluate how RAM capacity impacts user satisfaction across the Top 5 brands. Additionally, we will normalize our data to compare values comprehensively across the entire dataset.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\n(df\n .query(\"brand_name.isin(@top5_brand_names_ordered)\") # filter rows based on top10 brands\n .assign(brand_name=lambda df: df.brand_name.str.capitalize())\n .pipe(lambda df: pd.crosstab(index=df['ram_capacity'],\n                              columns=df['brand_name'],\n                              values=df['avg_rating'],\n                              aggfunc='mean',\n                              margins=True,\n                              normalize='all'\n                             )\n      )\n .mul(100)\n .round(1)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>brand_name</th>\n      <th>Oppo</th>\n      <th>Realme</th>\n      <th>Samsung</th>\n      <th>Vivo</th>\n      <th>Xiaomi</th>\n      <th>All</th>\n    </tr>\n    <tr>\n      <th>ram_capacity</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>2.7</td>\n      <td>2.8</td>\n      <td>2.7</td>\n      <td>2.7</td>\n      <td>11.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.9</td>\n      <td>2.8</td>\n      <td>2.9</td>\n      <td>2.9</td>\n      <td>2.8</td>\n      <td>12.1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.1</td>\n      <td>3.2</td>\n      <td>3.2</td>\n      <td>3.2</td>\n      <td>3.2</td>\n      <td>13.5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3.3</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.4</td>\n      <td>3.5</td>\n      <td>14.8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3.7</td>\n      <td>3.7</td>\n      <td>3.8</td>\n      <td>3.7</td>\n      <td>3.8</td>\n      <td>15.7</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>3.8</td>\n      <td>3.9</td>\n      <td>3.9</td>\n      <td>3.8</td>\n      <td>3.9</td>\n      <td>16.3</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>3.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>16.2</td>\n    </tr>\n    <tr>\n      <th>All</th>\n      <td>20.2</td>\n      <td>19.6</td>\n      <td>20.2</td>\n      <td>19.8</td>\n      <td>20.2</td>\n      <td>100.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nI hope this article has convinced you to pick up Matt Harrison's [Effective Pandas](https://store.metasnake.com/effective-pandas-book)! There are plenty more exciting ideas in the book beyond the Top 10 I've shared here (I didn't even get into the fascinating time series part!). I hope you found these insights helpful and inspiring.\n\nHappy coding üêºüíªüöÄ\n\n",
    "supporting": [
      "2023_08_02-Top_10_things_I_learned_from_Effective_Pandas_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}